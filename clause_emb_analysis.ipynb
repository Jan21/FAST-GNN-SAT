{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import models_with_args\n",
    "import numpy as np\n",
    "\n",
    "from pyunigen import Sampler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data.dataset import files_exist, __repr__\n",
    "from torch_sparse import SparseTensor\n",
    "import numpy as np\n",
    "import PyMiniSolvers.minisolvers as minisolvers\n",
    "from pysat.solvers import Glucose3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NeuroSATRNN'\n",
    "model_type = models_with_args[model_name]\n",
    "model_class = model_type['model_class']\n",
    "model_args = model_type['model_args']\n",
    "\n",
    "model = model_class(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"temp/tb_logs/Final/version_28/checkpoints/epoch=16-step=3332.ckpt\")\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    new_key = key[6:]  # Remove \"model.\" prefix\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuroSATRNN(\n",
      "  (L_init): Linear(in_features=1, out_features=32, bias=True)\n",
      "  (C_init): Linear(in_features=1, out_features=32, bias=True)\n",
      "  (LC_msgs): LCMessagesRNN()\n",
      "  (CL_msgs): CLMessagesRNN()\n",
      "  (L_vote): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (true_vec_mult): Linear(in_features=32, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0617, -0.3002,  0.1244, -0.9027,  0.0756, -0.9489, -0.0096, -0.2207,\n",
      "         -0.0958, -0.0605, -0.6417, -0.0467, -0.0131, -0.0133, -0.0684,  0.2073,\n",
      "          0.5979, -0.1113, -0.2064, -0.1717, -0.0651,  0.1142,  0.0578,  1.0465,\n",
      "         -0.8400, -0.6261,  0.0703, -0.0857,  0.0155,  0.6567, -0.0643, -0.0234]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "true_vec = new_state_dict[\"true_vec_mult.weight\"]\n",
    "print(true_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "num_iters = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem(Data):\n",
    "    # a Problem is a bipartite graph\n",
    "\n",
    "    def __init__(self, edge_index=None, x_l=None, x_c=None, y=None, clauses = None, sat_assignment=None, sampled_solutions=None):\n",
    "        # edge_index is a bipartite adjacency matrix between lits and clauses\n",
    "        # x_l is the feature vector of the lits nodes\n",
    "        # x_c is the feature vector of the clauses nodes\n",
    "        # y is the label: 1 if sat, 0 if unsat\n",
    "\n",
    "        super(Problem, self).__init__()\n",
    "        # nodes features\n",
    "        self.x_l = x_l\n",
    "        self.x_c = x_c\n",
    "        self.y = y\n",
    "        self.sat_assignment = sat_assignment\n",
    "        self.sampled_solutions = sampled_solutions\n",
    "\n",
    "        self.num_literals = x_l.size(0) if x_l is not None else 0\n",
    "        self.num_clauses = x_c.size(0) if x_c is not None else 0\n",
    "\n",
    "        # edges\n",
    "        self.edge_index = edge_index\n",
    "        self.adj_t = SparseTensor(row = edge_index[1],\n",
    "                                  col = edge_index[0],\n",
    "                                  sparse_sizes = [self.num_clauses, self.num_literals]\n",
    "                                 ) if edge_index is not None else 0\n",
    "\n",
    "        # compute number of variables\n",
    "        assert self.num_literals %2 == 0\n",
    "        self.num_vars = self.num_literals // 2\n",
    "\n",
    "        self.num_nodes = self.num_literals + self.num_clauses\n",
    "\n",
    "        self.clauses = clauses\n",
    "\n",
    "def parse_dimacs(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        i = 0\n",
    "        while lines[i].strip().split(\" \")[0] == \"c\":\n",
    "            # strip : remove spaces at the beginning and at the end of the string\n",
    "            i += 1\n",
    "\n",
    "        header = lines[i].strip().split(\" \")\n",
    "        assert(header[0] == 'p')\n",
    "        n_vars = int(header[2])\n",
    "        clauses = [[int(s) for s in line.strip().split(\" \")[:-1]] for line in lines[i+1:]]\n",
    "        return n_vars, clauses\n",
    "\n",
    "def create_problem(n_vars, clauses, y):\n",
    "        # d is the number of features of x_l and x_c\n",
    "\n",
    "        n_lits = int(2 * n_vars)\n",
    "        n_clauses = len(clauses)\n",
    "\n",
    "\n",
    "        #ADDED!\n",
    "        d = 16\n",
    "        l_init = torch.normal(mean=0.0, std=1.0, size=(1,d))\n",
    "        c_init = torch.normal(mean=0.0, std=1.0, size=(1,d)) \n",
    "        denom = torch.sqrt(torch.tensor(d, dtype=torch.float32))\n",
    "\n",
    "        # create feature vectors for lits and clauses\n",
    "        x_l = (torch.div(l_init, denom)).repeat(n_lits, 1)\n",
    "        x_c = (torch.div(c_init, denom)).repeat(n_clauses, 1)\n",
    "\n",
    "        # get graph edges from list of clauses\n",
    "        edge_index = [[],[]]\n",
    "        for i,clause in enumerate(clauses):\n",
    "            # get idxs of lits in clause\n",
    "            lits_indices = [from_lit_to_idx(l, n_vars) for l in clause]\n",
    "            clauses_indices = len(clause) * [i]\n",
    "\n",
    "            # add all edges connected to clause i to edge_index\n",
    "            edge_index[0].extend(lits_indices)\n",
    "            edge_index[1].extend(clauses_indices)\n",
    "\n",
    "        # convert edge_index to tensor\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "        if y:\n",
    "            solver = Glucose3()\n",
    "            for clause in clauses:\n",
    "                solver.add_clause(clause)\n",
    "            solver.solve()\n",
    "            satisfying_assignment = solver.get_model()\n",
    "\n",
    "            s = Sampler()\n",
    "            for cl in clauses:\n",
    "                s.add_clause(cl)\n",
    "            _, _, samples = s.sample(num=10)\n",
    "\n",
    "            unique_samples = []        \n",
    "            for sample in samples:\n",
    "                if sample not in unique_samples:\n",
    "                    unique_samples.append(sample)\n",
    "            \n",
    "\n",
    "            #cat_unique_samples = []\n",
    "            #for sample in unique_samples:\n",
    "            #    cat_unique_samples+=sample\n",
    "            #torch.tensor(np.sign(cat_unique_samples), dtype=torch.float)\n",
    "            samples_tensor = torch.tensor(np.sign(samples), dtype=torch.float).permute(1, 0)\n",
    "\n",
    "            prob = Problem(edge_index, x_l, x_c, y, clauses, torch.tensor(np.sign(satisfying_assignment), dtype=torch.float), samples_tensor) #\n",
    "            print(prob)\n",
    "            return prob\n",
    "        return Problem(edge_index, x_l, x_c, y, clauses)\n",
    "\n",
    "def solve_sat(n_vars, iclauses):\n",
    "    solver = minisolvers.MinisatSolver()\n",
    "\n",
    "    for i in range(n_vars):\n",
    "        solver.new_var(dvar=True) # dvar=True <- this var will be used as a decision var\n",
    "\n",
    "    for iclause in iclauses:\n",
    "        solver.add_clause(iclause)\n",
    "\n",
    "    is_sat = solver.solve()\n",
    "    stats = solver.get_stats() # dictionary of solver statistics\n",
    "\n",
    "    return is_sat, stats\n",
    "\n",
    "def from_lit_to_idx(lit, n_vars):\n",
    "        # from a literal in range {1,...n_vars,-1,...,-n_vars} get the literal\n",
    "        # index in {0,...,n_lits-1} = {0,...,2*n_vars-1}\n",
    "        # if l is positive l <- l-1\n",
    "        # if l in negative l <- n_vars-l-1\n",
    "        assert(lit!=0)\n",
    "        if lit > 0 :\n",
    "            return lit - 1\n",
    "        if lit < 0 :\n",
    "            return n_vars - lit - 1\n",
    "\n",
    "def from_index_to_lit(idx, n_vars):\n",
    "    # inverse of 'from_lit_to_idx', just in case\n",
    "    if idx < n_vars:\n",
    "        return idx+1\n",
    "    else:\n",
    "        return n_vars-idx-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(x_l=[80, 16], x_c=[276, 16], y=True, sat_assignment=[40], sampled_solutions=[40, 10], num_literals=80, num_clauses=276, edge_index=[2, 1169], adj_t=[276, 80, nnz=1169], num_vars=40, num_nodes=356, clauses=[276])\n",
      "['final_lits_votes', 'final_lits_mats', 'vote_mean_pool', 'final_truth_assignment', 'each_step_truth_assignments', 'clause_embs_all_steps', 'initial_truth_assignment']\n"
     ]
    }
   ],
   "source": [
    "raw_path = \"temp/cnfs/selsam_3_40/test/sr_n=0040_pk2=0.30_pg=0.40_t=0_sat=1.dimacs\"\n",
    "\n",
    "n_vars, clauses = parse_dimacs(raw_path)\n",
    "y, _ = solve_sat(n_vars, clauses)\n",
    "problem = create_problem(n_vars, clauses, y)\n",
    "\n",
    "single_loader = DataLoader([problem], follow_batch=['x_l','x_c'], batch_size=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    res = model(next(iter(single_loader)).to(device), 80)\n",
    "\n",
    "print(list(res.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_assignment = res[\"each_step_truth_assignments\"][5][0]\n",
    "bin_assignment = bin_assignment[:bin_assignment.shape[0]//2]\n",
    "bin_assignment = torch.sign(bin_assignment).cpu().squeeze(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_literals = []\n",
    "for ix, assignment in enumerate(bin_assignment):\n",
    "    result_literals.append(int((ix+1) * assignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "sat_num = 0\n",
    "for c in problem.clauses:\n",
    "    for lit in c:\n",
    "        if lit in result_literals:\n",
    "            sat_num +=1\n",
    "            break\n",
    "print(len(problem.clauses)-sat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/cnfs/3sat_100_400/test/cnt=38_cls=112_var=28_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=23_cls=208_var=52_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=70_cls=228_var=57_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=90_cls=164_var=41_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=55_cls=132_var=33_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=9_cls=396_var=99_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=59_cls=248_var=62_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=26_cls=200_var=50_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=88_cls=96_var=24_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=62_cls=332_var=83_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=67_cls=432_var=108_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=21_cls=128_var=32_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=34_cls=228_var=57_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=99_cls=200_var=50_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=22_cls=292_var=73_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=78_cls=252_var=63_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=15_cls=140_var=35_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=60_cls=428_var=107_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=16_cls=392_var=98_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=79_cls=252_var=63_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=77_cls=332_var=83_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=40_cls=184_var=46_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=87_cls=404_var=101_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=18_cls=228_var=57_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=2_cls=324_var=81_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=29_cls=312_var=78_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=33_cls=116_var=29_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=27_cls=436_var=109_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=6_cls=140_var=35_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=66_cls=372_var=93_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=11_cls=400_var=100_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=47_cls=344_var=86_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=52_cls=324_var=81_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=73_cls=244_var=61_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=93_cls=140_var=35_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=43_cls=224_var=56_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=76_cls=344_var=86_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=30_cls=188_var=47_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=20_cls=152_var=38_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=92_cls=128_var=32_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=8_cls=120_var=30_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=63_cls=280_var=70_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=31_cls=120_var=30_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=68_cls=260_var=65_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=37_cls=360_var=90_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=13_cls=372_var=93_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=96_cls=332_var=83_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=83_cls=144_var=36_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=80_cls=112_var=28_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=58_cls=144_var=36_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=65_cls=408_var=102_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=71_cls=88_var=22_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=19_cls=260_var=65_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=10_cls=332_var=83_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=86_cls=244_var=61_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=35_cls=80_var=20_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=56_cls=156_var=39_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=74_cls=168_var=42_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=85_cls=268_var=67_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=48_cls=176_var=44_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=32_cls=328_var=82_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=49_cls=440_var=110_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=50_cls=220_var=55_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=44_cls=372_var=93_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=98_cls=220_var=55_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=89_cls=260_var=65_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=4_cls=108_var=27_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=7_cls=272_var=68_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=25_cls=336_var=84_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=54_cls=392_var=98_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=57_cls=392_var=98_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=24_cls=200_var=50_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=95_cls=224_var=56_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=91_cls=396_var=99_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=61_cls=352_var=88_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=14_cls=304_var=76_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=41_cls=244_var=61_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=64_cls=188_var=47_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=53_cls=164_var=41_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=81_cls=404_var=101_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=28_cls=96_var=24_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=69_cls=84_var=21_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=0_cls=96_var=24_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=5_cls=348_var=87_sat=1.dimacs\n",
      "temp/cnfs/3sat_100_400/test/cnt=51_cls=432_var=108_sat=1.dimacs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_dir = \"temp/cnfs/3sat_100_400/test/\"\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(\"1.dimacs\"):\n",
    "        filepath = os.path.join(test_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "56\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "59\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "60\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "57\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "64\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "62\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "55\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "62\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "63\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "61\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n",
      "61\n",
      "Problem(x_l=[200, 16], x_c=[400, 16], y=True, sat_assignment=[100], sampled_solutions=[100, 10], num_literals=200, num_clauses=400, edge_index=[2, 1200], adj_t=[400, 200, nnz=1200], num_vars=100, num_nodes=600, clauses=[400])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m single_loader \u001b[38;5;241m=\u001b[39m DataLoader([problem], follow_batch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_l\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_c\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msingle_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m gap_by_iter \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/sat_gcn/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sat_gcn/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/FAST-GNN-REF/models/neurosat_architecture.py:289\u001b[0m, in \u001b[0;36mNeuroSATRNN.forward\u001b[0;34m(self, data, num_iters)\u001b[0m\n\u001b[1;32m    287\u001b[0m clause_embs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[0;32m--> 289\u001b[0m     x_c_\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC_msgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     x_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCL_msgs(adj_t, x_c_, x_l, x_l_batch)\n\u001b[1;32m    291\u001b[0m     x_l \u001b[38;5;241m=\u001b[39m x_l \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(x_l, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sat_gcn/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(200):\n",
    "    raw_path = \"temp/cnfs/3sat_100_400/val/cnt=33_cls=400_var=100_sat=1.dimacs\"\n",
    "\n",
    "    n_vars, clauses = parse_dimacs(raw_path)\n",
    "    y, _ = solve_sat(n_vars, clauses)\n",
    "    problem = create_problem(n_vars, clauses, y)\n",
    "\n",
    "    single_loader = DataLoader([problem], follow_batch=['x_l','x_c'], batch_size=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        res = model(next(iter(single_loader)).to(device), 300)\n",
    "\n",
    "\n",
    "    gap_by_iter = []\n",
    "    for it in range(300):\n",
    "        bin_assignment = res[\"each_step_truth_assignments\"][it][0]\n",
    "        bin_assignment = bin_assignment[:bin_assignment.shape[0]//2]\n",
    "        bin_assignment = torch.sign(bin_assignment).cpu().squeeze(1).numpy()\n",
    "\n",
    "        result_literals = []\n",
    "        for ix, assignment in enumerate(bin_assignment):\n",
    "            result_literals.append(int((ix+1) * assignment))\n",
    "            sat_num = 0\n",
    "        for c in problem.clauses:\n",
    "            for lit in c:\n",
    "                if lit in result_literals:\n",
    "                    sat_num +=1\n",
    "                    break\n",
    "        gap_by_iter.append(len(problem.clauses)-sat_num)\n",
    "    print(gap_by_iter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66,\n",
       " 44,\n",
       " 32,\n",
       " 44,\n",
       " 34,\n",
       " 49,\n",
       " 33,\n",
       " 44,\n",
       " 35,\n",
       " 40,\n",
       " 37,\n",
       " 41,\n",
       " 35,\n",
       " 41,\n",
       " 35,\n",
       " 44,\n",
       " 37,\n",
       " 45,\n",
       " 37,\n",
       " 49,\n",
       " 35,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49,\n",
       " 36,\n",
       " 49]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_by_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(gap_by_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 gap: 38\n",
      "Iter: 1 gap: 49\n",
      "Iter: 2 gap: 32\n",
      "Iter: 3 gap: 26\n",
      "Iter: 4 gap: 31\n",
      "Iter: 5 gap: 26\n",
      "Iter: 6 gap: 29\n",
      "Iter: 7 gap: 25\n",
      "Iter: 8 gap: 14\n",
      "Iter: 9 gap: 17\n",
      "Iter: 10 gap: 14\n",
      "Iter: 11 gap: 11\n",
      "Iter: 12 gap: 12\n",
      "Iter: 13 gap: 9\n",
      "Iter: 14 gap: 7\n",
      "Iter: 15 gap: 10\n",
      "Iter: 16 gap: 11\n",
      "Iter: 17 gap: 8\n",
      "Iter: 18 gap: 7\n",
      "Iter: 19 gap: 8\n",
      "Iter: 20 gap: 7\n",
      "Iter: 21 gap: 7\n",
      "Iter: 22 gap: 6\n",
      "Iter: 23 gap: 7\n",
      "Iter: 24 gap: 6\n",
      "Iter: 25 gap: 7\n",
      "Iter: 26 gap: 11\n",
      "Iter: 27 gap: 8\n",
      "Iter: 28 gap: 6\n",
      "Iter: 29 gap: 7\n",
      "Iter: 30 gap: 6\n",
      "Iter: 31 gap: 7\n",
      "Iter: 32 gap: 6\n",
      "Iter: 33 gap: 7\n",
      "Iter: 34 gap: 5\n",
      "Iter: 35 gap: 7\n",
      "Iter: 36 gap: 6\n",
      "Iter: 37 gap: 8\n",
      "Iter: 38 gap: 7\n",
      "Iter: 39 gap: 9\n",
      "Iter: 40 gap: 5\n",
      "Iter: 41 gap: 10\n",
      "Iter: 42 gap: 4\n",
      "Iter: 43 gap: 7\n",
      "Iter: 44 gap: 3\n",
      "Iter: 45 gap: 4\n",
      "Iter: 46 gap: 2\n",
      "Iter: 47 gap: 3\n",
      "Iter: 48 gap: 2\n",
      "Iter: 49 gap: 4\n",
      "Iter: 50 gap: 4\n",
      "Iter: 51 gap: 4\n",
      "Iter: 52 gap: 4\n",
      "Iter: 53 gap: 4\n",
      "Iter: 54 gap: 4\n",
      "Iter: 55 gap: 4\n",
      "Iter: 56 gap: 4\n",
      "Iter: 57 gap: 2\n",
      "Iter: 58 gap: 2\n",
      "Iter: 59 gap: 2\n",
      "Iter: 60 gap: 4\n",
      "Iter: 61 gap: 4\n",
      "Iter: 62 gap: 5\n",
      "Iter: 63 gap: 5\n",
      "Iter: 64 gap: 4\n",
      "Iter: 65 gap: 2\n",
      "Iter: 66 gap: 2\n",
      "Iter: 67 gap: 2\n",
      "Iter: 68 gap: 2\n",
      "Iter: 69 gap: 1\n",
      "Iter: 70 gap: 1\n",
      "Iter: 71 gap: 2\n",
      "Iter: 72 gap: 4\n",
      "Iter: 73 gap: 4\n",
      "Iter: 74 gap: 4\n",
      "Iter: 75 gap: 4\n",
      "Iter: 76 gap: 1\n",
      "Iter: 77 gap: 1\n",
      "Iter: 78 gap: 5\n",
      "Iter: 79 gap: 3\n",
      "Iter: 80 gap: 3\n"
     ]
    }
   ],
   "source": [
    "for ix, num in enumerate(gap_by_iter):\n",
    "    print(f\"Iter: {ix} gap: {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/cnfs/3sat_100_400/val/cnt=33_cls=400_var=100_sat=1.dimacs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_dir = \"temp/cnfs/3sat_100_400/val/\"\n",
    "all_gaps = []\n",
    "starting_gap_value = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(\"1.dimacs\"):\n",
    "        raw_path = filepath = os.path.join(test_dir, filename)\n",
    "        n_vars, clauses = parse_dimacs(raw_path)\n",
    "        y, _ = solve_sat(n_vars, clauses)\n",
    "        problem = create_problem(n_vars, clauses, y)\n",
    "\n",
    "        single_loader = DataLoader([problem], follow_batch=['x_l','x_c'], batch_size=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = model(next(iter(single_loader)).to(device), 80)\n",
    "\n",
    "\n",
    "        gap_by_iter = []\n",
    "        for it in range(80):\n",
    "            bin_assignment = res[\"each_step_truth_assignments\"][it][0]\n",
    "            bin_assignment = bin_assignment[:bin_assignment.shape[0]//2]\n",
    "            bin_assignment = torch.sign(bin_assignment).cpu().squeeze(1).numpy()\n",
    "\n",
    "            result_literals = []\n",
    "            for ix, assignment in enumerate(bin_assignment):\n",
    "                result_literals.append(int((ix+1) * assignment))\n",
    "                sat_num = 0\n",
    "            for c in problem.clauses:\n",
    "                for lit in c:\n",
    "                    if lit in result_literals:\n",
    "                        sat_num +=1\n",
    "                        break\n",
    "            gap_by_iter.append(len(problem.clauses)-sat_num)\n",
    "        starting_gap_value.append(gap_by_iter[0])\n",
    "        all_gaps.append(np.min(gap_by_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3516483516483517"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 22,\n",
       " 0,\n",
       " 15,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 26,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 23,\n",
       " 0,\n",
       " 21,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 23,\n",
       " 2,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 14,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 28,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63,\n",
       " 34,\n",
       " 48,\n",
       " 38,\n",
       " 42,\n",
       " 45,\n",
       " 53,\n",
       " 28,\n",
       " 51,\n",
       " 49,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 52,\n",
       " 48,\n",
       " 53,\n",
       " 44,\n",
       " 43,\n",
       " 48,\n",
       " 45,\n",
       " 50,\n",
       " 45,\n",
       " 57,\n",
       " 58,\n",
       " 40,\n",
       " 45,\n",
       " 66,\n",
       " 47,\n",
       " 49,\n",
       " 56,\n",
       " 57,\n",
       " 40,\n",
       " 40,\n",
       " 62,\n",
       " 53,\n",
       " 48,\n",
       " 48,\n",
       " 34,\n",
       " 50,\n",
       " 54,\n",
       " 52,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 45,\n",
       " 47,\n",
       " 47,\n",
       " 50,\n",
       " 52,\n",
       " 57,\n",
       " 49,\n",
       " 42,\n",
       " 49,\n",
       " 47,\n",
       " 59,\n",
       " 65,\n",
       " 50,\n",
       " 52,\n",
       " 32,\n",
       " 41,\n",
       " 42,\n",
       " 50,\n",
       " 60,\n",
       " 55,\n",
       " 44,\n",
       " 59,\n",
       " 57,\n",
       " 58,\n",
       " 56,\n",
       " 60,\n",
       " 61,\n",
       " 47,\n",
       " 46,\n",
       " 51,\n",
       " 45,\n",
       " 47,\n",
       " 58,\n",
       " 49,\n",
       " 46,\n",
       " 41,\n",
       " 51,\n",
       " 63,\n",
       " 47,\n",
       " 39,\n",
       " 54,\n",
       " 52,\n",
       " 64,\n",
       " 58,\n",
       " 60,\n",
       " 44,\n",
       " 65,\n",
       " 43,\n",
       " 49,\n",
       " 51,\n",
       " 47,\n",
       " 40,\n",
       " 36,\n",
       " 47,\n",
       " 48,\n",
       " 45,\n",
       " 37,\n",
       " 49,\n",
       " 53,\n",
       " 59,\n",
       " 51,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 56,\n",
       " 52,\n",
       " 47,\n",
       " 58,\n",
       " 45,\n",
       " 46,\n",
       " 63,\n",
       " 44,\n",
       " 41,\n",
       " 53,\n",
       " 47,\n",
       " 50,\n",
       " 53,\n",
       " 53,\n",
       " 49,\n",
       " 45,\n",
       " 54,\n",
       " 60,\n",
       " 46,\n",
       " 53,\n",
       " 54,\n",
       " 50,\n",
       " 51,\n",
       " 45,\n",
       " 50,\n",
       " 56,\n",
       " 46,\n",
       " 56,\n",
       " 51,\n",
       " 60,\n",
       " 41,\n",
       " 43,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 59,\n",
       " 52,\n",
       " 49,\n",
       " 53,\n",
       " 39,\n",
       " 61,\n",
       " 52,\n",
       " 63,\n",
       " 41,\n",
       " 56,\n",
       " 50,\n",
       " 51,\n",
       " 39,\n",
       " 46,\n",
       " 53,\n",
       " 41,\n",
       " 41,\n",
       " 55,\n",
       " 53,\n",
       " 57,\n",
       " 48,\n",
       " 48,\n",
       " 46,\n",
       " 55,\n",
       " 50,\n",
       " 48,\n",
       " 48,\n",
       " 51,\n",
       " 55,\n",
       " 50,\n",
       " 45,\n",
       " 58,\n",
       " 47,\n",
       " 40,\n",
       " 51,\n",
       " 46,\n",
       " 51,\n",
       " 51,\n",
       " 38]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_gap_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat_gcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

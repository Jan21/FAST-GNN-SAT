{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "with open('../temp/embs_150.pkl', 'rb') as f:\n",
    "    embs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-67ceae6bf383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mscores_with_labels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clustering_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mscores_with_labels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-67ceae6bf383>\u001b[0m in \u001b[0;36mget_clustering_score\u001b[0;34m(embedding)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_clustering_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclusterer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msilhouette_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msilhouette_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \"\"\"\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                 \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m             )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, x_squared_norms, tol, n_threads)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# compute new pairwise distances between centers and closest other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# center of each center for next iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mcenter_half_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         distance_next_center = np.partition(\n\u001b[1;32m    493\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_half_distances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    328\u001b[0m             )\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# To minimize precision issues with float32, we compute the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# matrix on chunks of X and Y upcast to float64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_euclidean_distances_upcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mx_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mXX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mgen_batches\u001b[0;34m(n, batch_size, min_batch_size)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \"\"\"\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         raise TypeError(\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"gen_batches got batch_size=%s, must be an integer\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cluster emb with kmeans and compute clustering coefficient\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def get_clustering_score(embedding):\n",
    "    clusterer = KMeans(n_clusters=2, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(embedding)\n",
    "    silhouette_avg = silhouette_score(embedding, cluster_labels)\n",
    "    return silhouette_avg\n",
    "\n",
    "scores_with_labels_train = []\n",
    "scores_with_labels_test = []\n",
    "for i in embs['train']:\n",
    "    score = get_clustering_score(i['embs'])\n",
    "    scores_with_labels_train.append((score,int(i['y'][0])))\n",
    "for i in embs['test']:\n",
    "    score = get_clustering_score(i['embs'])\n",
    "    scores_with_labels_test.append((score,int(i['y'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_with_labels_train.sort(key=lambda x: x[0], reverse=True)\n",
    "labels = [l for s,l in scores_with_labels_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8531033, 1),\n",
       " (0.80788547, 1),\n",
       " (0.8077914, 1),\n",
       " (0.80743945, 1),\n",
       " (0.7982832, 1),\n",
       " (0.79752755, 1),\n",
       " (0.796381, 1),\n",
       " (0.79513615, 1),\n",
       " (0.79424584, 1),\n",
       " (0.7921556, 1),\n",
       " (0.7896109, 1),\n",
       " (0.7893833, 1),\n",
       " (0.788917, 1),\n",
       " (0.7878195, 1),\n",
       " (0.7874459, 1),\n",
       " (0.7840251, 1),\n",
       " (0.7798263, 1),\n",
       " (0.7756173, 1),\n",
       " (0.7752906, 1),\n",
       " (0.77514946, 1),\n",
       " (0.77359784, 1),\n",
       " (0.7727221, 1),\n",
       " (0.77229154, 1),\n",
       " (0.77190477, 1),\n",
       " (0.77175224, 1),\n",
       " (0.7710217, 1),\n",
       " (0.76960117, 1),\n",
       " (0.76713777, 1),\n",
       " (0.76407206, 1),\n",
       " (0.7606886, 1),\n",
       " (0.75907004, 1),\n",
       " (0.7584586, 1),\n",
       " (0.75778985, 1),\n",
       " (0.75777704, 1),\n",
       " (0.7570033, 1),\n",
       " (0.7551208, 1),\n",
       " (0.7538001, 1),\n",
       " (0.75310725, 1),\n",
       " (0.75257844, 1),\n",
       " (0.75137365, 1),\n",
       " (0.75119096, 1),\n",
       " (0.7497859, 1),\n",
       " (0.74752325, 1),\n",
       " (0.7473325, 1),\n",
       " (0.74522144, 1),\n",
       " (0.7439779, 1),\n",
       " (0.74384135, 1),\n",
       " (0.7426074, 1),\n",
       " (0.7425889, 1),\n",
       " (0.7408212, 1),\n",
       " (0.73882926, 1),\n",
       " (0.7384659, 1),\n",
       " (0.73687047, 1),\n",
       " (0.73568594, 1),\n",
       " (0.7351522, 1),\n",
       " (0.73453486, 1),\n",
       " (0.73374015, 1),\n",
       " (0.733644, 1),\n",
       " (0.73317385, 1),\n",
       " (0.7329698, 1),\n",
       " (0.7322984, 1),\n",
       " (0.7312058, 1),\n",
       " (0.7310327, 1),\n",
       " (0.7303848, 1),\n",
       " (0.7302898, 1),\n",
       " (0.7296691, 1),\n",
       " (0.72962236, 1),\n",
       " (0.7268337, 1),\n",
       " (0.7259458, 1),\n",
       " (0.72510445, 1),\n",
       " (0.72485936, 1),\n",
       " (0.7240758, 1),\n",
       " (0.72264165, 1),\n",
       " (0.7226016, 1),\n",
       " (0.7223374, 1),\n",
       " (0.7221581, 1),\n",
       " (0.7206684, 1),\n",
       " (0.7201971, 1),\n",
       " (0.7183681, 1),\n",
       " (0.71829414, 1),\n",
       " (0.71726274, 1),\n",
       " (0.71606505, 1),\n",
       " (0.715212, 1),\n",
       " (0.7144106, 1),\n",
       " (0.7136582, 1),\n",
       " (0.7136271, 1),\n",
       " (0.7124073, 1),\n",
       " (0.7123834, 1),\n",
       " (0.7119105, 1),\n",
       " (0.7098262, 1),\n",
       " (0.7096664, 1),\n",
       " (0.7079109, 1),\n",
       " (0.7079002, 1),\n",
       " (0.70784885, 1),\n",
       " (0.70718277, 1),\n",
       " (0.70712733, 1),\n",
       " (0.70644605, 1),\n",
       " (0.70634806, 1),\n",
       " (0.7061264, 1),\n",
       " (0.7048642, 1),\n",
       " (0.70483416, 1),\n",
       " (0.70469713, 1),\n",
       " (0.70401984, 1),\n",
       " (0.703573, 1),\n",
       " (0.70355356, 1),\n",
       " (0.7032758, 1),\n",
       " (0.70254695, 1),\n",
       " (0.7020257, 1),\n",
       " (0.70173514, 1),\n",
       " (0.7009748, 1),\n",
       " (0.7006912, 1),\n",
       " (0.700684, 1),\n",
       " (0.7004781, 1),\n",
       " (0.69977975, 1),\n",
       " (0.6994048, 1),\n",
       " (0.6992618, 1),\n",
       " (0.6983616, 1),\n",
       " (0.6972132, 1),\n",
       " (0.69694954, 1),\n",
       " (0.69664717, 1),\n",
       " (0.69539946, 1),\n",
       " (0.6948776, 1),\n",
       " (0.6946949, 1),\n",
       " (0.6945936, 1),\n",
       " (0.69385064, 1),\n",
       " (0.6935824, 1),\n",
       " (0.6935126, 1),\n",
       " (0.69318116, 1),\n",
       " (0.69312364, 1),\n",
       " (0.69301134, 1),\n",
       " (0.69293565, 1),\n",
       " (0.69251007, 1),\n",
       " (0.69249904, 1),\n",
       " (0.69208354, 1),\n",
       " (0.69161904, 1),\n",
       " (0.69137275, 1),\n",
       " (0.6899709, 1),\n",
       " (0.6881267, 1),\n",
       " (0.6867012, 1),\n",
       " (0.6866757, 1),\n",
       " (0.68663156, 1),\n",
       " (0.6842891, 1),\n",
       " (0.68373835, 0),\n",
       " (0.68289757, 1),\n",
       " (0.68273056, 1),\n",
       " (0.68264306, 1),\n",
       " (0.6823846, 1),\n",
       " (0.682078, 1),\n",
       " (0.68150777, 1),\n",
       " (0.6810212, 1),\n",
       " (0.6802525, 1),\n",
       " (0.67997754, 1),\n",
       " (0.67996866, 1),\n",
       " (0.67993516, 1),\n",
       " (0.6798938, 1),\n",
       " (0.67864525, 1),\n",
       " (0.67832464, 1),\n",
       " (0.6781262, 1),\n",
       " (0.67809254, 1),\n",
       " (0.6779278, 1),\n",
       " (0.6772494, 1),\n",
       " (0.6755952, 1),\n",
       " (0.674751, 1),\n",
       " (0.6744024, 1),\n",
       " (0.6742466, 1),\n",
       " (0.6737868, 1),\n",
       " (0.67280227, 1),\n",
       " (0.672084, 1),\n",
       " (0.6703789, 1),\n",
       " (0.66966546, 1),\n",
       " (0.6696002, 1),\n",
       " (0.6687223, 1),\n",
       " (0.6686926, 1),\n",
       " (0.6684289, 1),\n",
       " (0.6683278, 1),\n",
       " (0.6677965, 1),\n",
       " (0.6676115, 1),\n",
       " (0.667127, 1),\n",
       " (0.66700524, 1),\n",
       " (0.6656515, 1),\n",
       " (0.6649946, 1),\n",
       " (0.6644887, 1),\n",
       " (0.66393787, 1),\n",
       " (0.66311103, 1),\n",
       " (0.6629149, 1),\n",
       " (0.66267765, 1),\n",
       " (0.6619097, 1),\n",
       " (0.6614573, 1),\n",
       " (0.66141665, 1),\n",
       " (0.6605738, 1),\n",
       " (0.6595762, 1),\n",
       " (0.6585801, 1),\n",
       " (0.65848505, 1),\n",
       " (0.657652, 0),\n",
       " (0.6573571, 1),\n",
       " (0.6564392, 1),\n",
       " (0.65584314, 1),\n",
       " (0.6556688, 1),\n",
       " (0.6542481, 1),\n",
       " (0.6531155, 1),\n",
       " (0.6527954, 1),\n",
       " (0.65179473, 1),\n",
       " (0.6510128, 1),\n",
       " (0.6509555, 1),\n",
       " (0.650666, 1),\n",
       " (0.65065926, 1),\n",
       " (0.6489601, 1),\n",
       " (0.64887893, 1),\n",
       " (0.64879405, 1),\n",
       " (0.6481452, 1),\n",
       " (0.6456262, 1),\n",
       " (0.64541066, 1),\n",
       " (0.6450871, 1),\n",
       " (0.64178467, 1),\n",
       " (0.64146364, 1),\n",
       " (0.63952106, 1),\n",
       " (0.6389408, 1),\n",
       " (0.6384829, 1),\n",
       " (0.63837844, 1),\n",
       " (0.6379854, 1),\n",
       " (0.63788855, 1),\n",
       " (0.6375648, 1),\n",
       " (0.6371025, 1),\n",
       " (0.6361438, 1),\n",
       " (0.63570964, 1),\n",
       " (0.63437194, 1),\n",
       " (0.6339454, 0),\n",
       " (0.6335901, 1),\n",
       " (0.63306606, 1),\n",
       " (0.6330347, 1),\n",
       " (0.6324512, 1),\n",
       " (0.6303876, 1),\n",
       " (0.6295506, 1),\n",
       " (0.62926674, 0),\n",
       " (0.62848735, 1),\n",
       " (0.62807447, 1),\n",
       " (0.6278888, 1),\n",
       " (0.6258123, 1),\n",
       " (0.6250783, 1),\n",
       " (0.6237416, 1),\n",
       " (0.62192786, 1),\n",
       " (0.6212371, 1),\n",
       " (0.6184258, 1),\n",
       " (0.6167933, 1),\n",
       " (0.61600953, 1),\n",
       " (0.61588925, 0),\n",
       " (0.6141999, 0),\n",
       " (0.6112586, 1),\n",
       " (0.60844547, 0),\n",
       " (0.60679317, 1),\n",
       " (0.60256577, 1),\n",
       " (0.6010734, 0),\n",
       " (0.600696, 1),\n",
       " (0.5982069, 0),\n",
       " (0.5980422, 1),\n",
       " (0.59727365, 0),\n",
       " (0.59586877, 0),\n",
       " (0.59207934, 0),\n",
       " (0.5917972, 1),\n",
       " (0.5876253, 1),\n",
       " (0.58665, 0),\n",
       " (0.5823618, 0),\n",
       " (0.5810471, 0),\n",
       " (0.58076704, 1),\n",
       " (0.57527924, 0),\n",
       " (0.5745565, 0),\n",
       " (0.5735501, 1),\n",
       " (0.5726924, 0),\n",
       " (0.5725944, 0),\n",
       " (0.57218724, 0),\n",
       " (0.5711016, 0),\n",
       " (0.5709341, 0),\n",
       " (0.5702817, 0),\n",
       " (0.56914365, 0),\n",
       " (0.5687234, 0),\n",
       " (0.56849277, 0),\n",
       " (0.56790525, 0),\n",
       " (0.5670285, 1),\n",
       " (0.56533134, 0),\n",
       " (0.5648367, 0),\n",
       " (0.5648216, 0),\n",
       " (0.5588995, 0),\n",
       " (0.5587552, 0),\n",
       " (0.5575415, 0),\n",
       " (0.557536, 0),\n",
       " (0.55584943, 0),\n",
       " (0.55320007, 0),\n",
       " (0.5528153, 0),\n",
       " (0.5525265, 1),\n",
       " (0.5504719, 0),\n",
       " (0.5502915, 0),\n",
       " (0.5495914, 0),\n",
       " (0.54908764, 0),\n",
       " (0.548849, 0),\n",
       " (0.54761904, 0),\n",
       " (0.5472114, 0),\n",
       " (0.5458929, 0),\n",
       " (0.54567045, 1),\n",
       " (0.5453006, 0),\n",
       " (0.5448606, 0),\n",
       " (0.54344785, 0),\n",
       " (0.54325086, 1),\n",
       " (0.54317695, 0),\n",
       " (0.5431035, 0),\n",
       " (0.54095995, 0),\n",
       " (0.54070693, 0),\n",
       " (0.5404669, 0),\n",
       " (0.54004794, 0),\n",
       " (0.53835875, 0),\n",
       " (0.5364994, 0),\n",
       " (0.53637683, 0),\n",
       " (0.5362467, 0),\n",
       " (0.53597486, 0),\n",
       " (0.53575313, 0),\n",
       " (0.53432924, 0),\n",
       " (0.5341328, 0),\n",
       " (0.5332015, 0),\n",
       " (0.5320302, 0),\n",
       " (0.5298709, 0),\n",
       " (0.5293396, 0),\n",
       " (0.52723026, 1),\n",
       " (0.526999, 0),\n",
       " (0.5266458, 0),\n",
       " (0.5250829, 0),\n",
       " (0.52458227, 0),\n",
       " (0.5244157, 1),\n",
       " (0.5244075, 0),\n",
       " (0.52396923, 1),\n",
       " (0.5238544, 0),\n",
       " (0.5234398, 0),\n",
       " (0.5231811, 0),\n",
       " (0.5226768, 0),\n",
       " (0.5225466, 0),\n",
       " (0.5222591, 1),\n",
       " (0.5221643, 0),\n",
       " (0.5215638, 0),\n",
       " (0.52154934, 0),\n",
       " (0.5212494, 0),\n",
       " (0.52000254, 1),\n",
       " (0.5199916, 0),\n",
       " (0.5196392, 0),\n",
       " (0.5181222, 0),\n",
       " (0.51703274, 0),\n",
       " (0.51684743, 1),\n",
       " (0.51631373, 1),\n",
       " (0.5157631, 0),\n",
       " (0.5145466, 0),\n",
       " (0.5139041, 0),\n",
       " (0.5136323, 0),\n",
       " (0.51352257, 0),\n",
       " (0.51339453, 0),\n",
       " (0.5128854, 1),\n",
       " (0.51232433, 0),\n",
       " (0.51192605, 0),\n",
       " (0.5101579, 0),\n",
       " (0.5095568, 0),\n",
       " (0.50925505, 0),\n",
       " (0.5068812, 0),\n",
       " (0.504239, 0),\n",
       " (0.5036403, 1),\n",
       " (0.50293744, 0),\n",
       " (0.5022212, 0),\n",
       " (0.50215703, 0),\n",
       " (0.50203925, 1),\n",
       " (0.5019754, 0),\n",
       " (0.501218, 1),\n",
       " (0.50077325, 1),\n",
       " (0.50028485, 0),\n",
       " (0.5001172, 0),\n",
       " (0.49951687, 0),\n",
       " (0.4981369, 1),\n",
       " (0.49756774, 0),\n",
       " (0.49753636, 0),\n",
       " (0.4975265, 0),\n",
       " (0.49712548, 0),\n",
       " (0.49703732, 0),\n",
       " (0.49629012, 0),\n",
       " (0.49570608, 1),\n",
       " (0.49532685, 0),\n",
       " (0.49515113, 0),\n",
       " (0.4936034, 0),\n",
       " (0.4931776, 0),\n",
       " (0.49295694, 0),\n",
       " (0.49265915, 1),\n",
       " (0.492344, 0),\n",
       " (0.49043268, 0),\n",
       " (0.49007684, 0),\n",
       " (0.49005705, 0),\n",
       " (0.4893128, 0),\n",
       " (0.48916578, 1),\n",
       " (0.48915702, 0),\n",
       " (0.48915404, 0),\n",
       " (0.48653412, 0),\n",
       " (0.48621053, 0),\n",
       " (0.48574895, 0),\n",
       " (0.48488027, 0),\n",
       " (0.48483735, 0),\n",
       " (0.4847479, 0),\n",
       " (0.4845768, 0),\n",
       " (0.48434144, 0),\n",
       " (0.484332, 0),\n",
       " (0.4842201, 0),\n",
       " (0.483936, 1),\n",
       " (0.48248205, 0),\n",
       " (0.48234373, 0),\n",
       " (0.48213997, 0),\n",
       " (0.48199278, 0),\n",
       " (0.48130465, 0),\n",
       " (0.48088056, 1),\n",
       " (0.4790763, 0),\n",
       " (0.47844037, 0),\n",
       " (0.47793847, 0),\n",
       " (0.4768117, 0),\n",
       " (0.4765853, 0),\n",
       " (0.47634822, 0),\n",
       " (0.47626504, 0),\n",
       " (0.47569618, 0),\n",
       " (0.47512168, 0),\n",
       " (0.47416306, 0),\n",
       " (0.4739147, 0),\n",
       " (0.47328645, 0),\n",
       " (0.4730278, 0),\n",
       " (0.4729674, 0),\n",
       " (0.4727332, 0),\n",
       " (0.47230273, 0),\n",
       " (0.4692691, 0),\n",
       " (0.46907955, 0),\n",
       " (0.4689371, 0),\n",
       " (0.46822724, 0),\n",
       " (0.46591195, 1),\n",
       " (0.4657561, 0),\n",
       " (0.465133, 1),\n",
       " (0.46475267, 0),\n",
       " (0.4634262, 0),\n",
       " (0.4627425, 0),\n",
       " (0.46224052, 0),\n",
       " (0.46212602, 0),\n",
       " (0.46181202, 0),\n",
       " (0.46162575, 0),\n",
       " (0.46110648, 0),\n",
       " (0.46110457, 1),\n",
       " (0.46048823, 0),\n",
       " (0.46021047, 0),\n",
       " (0.45989743, 0),\n",
       " (0.4596935, 0),\n",
       " (0.45965642, 0),\n",
       " (0.45962852, 0),\n",
       " (0.4583128, 0),\n",
       " (0.45763367, 0),\n",
       " (0.4564069, 0),\n",
       " (0.4563656, 1),\n",
       " (0.45569485, 0),\n",
       " (0.4555276, 0),\n",
       " (0.45550528, 0),\n",
       " (0.45547968, 0),\n",
       " (0.4551653, 0),\n",
       " (0.45478517, 0),\n",
       " (0.45424598, 0),\n",
       " (0.45416164, 0),\n",
       " (0.45291463, 0),\n",
       " (0.45277137, 1),\n",
       " (0.45178923, 0),\n",
       " (0.45145255, 0),\n",
       " (0.45102087, 0),\n",
       " (0.45075828, 0),\n",
       " (0.45023003, 0),\n",
       " (0.45003423, 0),\n",
       " (0.44990253, 0),\n",
       " (0.44927484, 0),\n",
       " (0.44904456, 1),\n",
       " (0.44898063, 0),\n",
       " (0.44838977, 0),\n",
       " (0.44802827, 1),\n",
       " (0.44767705, 1),\n",
       " (0.4474514, 0),\n",
       " (0.4455594, 0),\n",
       " (0.4449957, 0),\n",
       " (0.44414538, 0),\n",
       " (0.44412407, 0),\n",
       " (0.44380766, 0),\n",
       " (0.44333115, 0),\n",
       " (0.44281355, 0),\n",
       " (0.4427759, 1),\n",
       " (0.4419759, 0),\n",
       " (0.4419325, 0),\n",
       " (0.44134673, 0),\n",
       " (0.44130975, 0),\n",
       " (0.4412612, 0),\n",
       " (0.4398291, 0),\n",
       " (0.43876952, 0),\n",
       " (0.43816763, 0),\n",
       " (0.43789357, 0),\n",
       " (0.43726435, 0),\n",
       " (0.4371539, 0),\n",
       " (0.43659896, 0),\n",
       " (0.43612418, 0),\n",
       " (0.43576616, 1),\n",
       " (0.43461233, 0),\n",
       " (0.4345645, 0),\n",
       " (0.43424672, 0),\n",
       " (0.43399993, 0),\n",
       " (0.43393502, 0),\n",
       " (0.43390903, 0),\n",
       " (0.43379766, 0),\n",
       " (0.4332028, 1),\n",
       " (0.43278518, 0),\n",
       " (0.4313263, 0),\n",
       " (0.43100625, 0),\n",
       " (0.43040913, 1),\n",
       " (0.42952937, 0),\n",
       " (0.4288122, 0),\n",
       " (0.42740116, 0),\n",
       " (0.42733988, 0),\n",
       " (0.4260909, 0),\n",
       " (0.42504144, 0),\n",
       " (0.4250353, 0),\n",
       " (0.42231935, 1),\n",
       " (0.42126045, 0),\n",
       " (0.42000455, 0),\n",
       " (0.41964483, 0),\n",
       " (0.4192787, 1),\n",
       " (0.41859183, 0),\n",
       " (0.41848525, 0),\n",
       " (0.41844016, 1),\n",
       " (0.41780406, 0),\n",
       " (0.41751766, 1),\n",
       " (0.41726708, 0),\n",
       " (0.41701278, 0),\n",
       " (0.41669378, 0),\n",
       " (0.41647595, 0),\n",
       " (0.41483003, 0),\n",
       " (0.41397518, 0),\n",
       " (0.4138783, 0),\n",
       " (0.41363686, 0),\n",
       " (0.41347224, 0),\n",
       " (0.4128906, 0),\n",
       " (0.4116432, 0),\n",
       " (0.4114697, 0),\n",
       " (0.41118106, 0),\n",
       " (0.41083878, 1),\n",
       " (0.41064787, 0),\n",
       " (0.41045934, 0),\n",
       " (0.40922594, 0),\n",
       " (0.409043, 0),\n",
       " (0.4078207, 0),\n",
       " (0.40712577, 1),\n",
       " (0.40681666, 0),\n",
       " (0.4066578, 0),\n",
       " (0.40462846, 0),\n",
       " (0.404321, 0),\n",
       " (0.40190092, 0),\n",
       " (0.40183368, 0),\n",
       " (0.40178174, 0),\n",
       " (0.40150946, 1),\n",
       " (0.39917108, 0),\n",
       " (0.39839786, 0),\n",
       " (0.39786735, 0),\n",
       " (0.39733952, 0),\n",
       " (0.3973168, 0),\n",
       " (0.39689055, 0),\n",
       " (0.39677298, 1),\n",
       " (0.39611712, 0),\n",
       " (0.39327082, 0),\n",
       " (0.39254904, 0),\n",
       " (0.39198977, 0),\n",
       " (0.39120358, 0),\n",
       " (0.3908103, 0),\n",
       " (0.39077562, 0),\n",
       " (0.38837653, 1),\n",
       " (0.38628662, 0),\n",
       " (0.3853429, 1),\n",
       " (0.3843675, 0),\n",
       " (0.384342, 0),\n",
       " (0.38382164, 0),\n",
       " (0.3780294, 0),\n",
       " (0.37776837, 0),\n",
       " (0.37664193, 0),\n",
       " (0.37649482, 0),\n",
       " (0.374892, 0),\n",
       " (0.3738895, 1),\n",
       " (0.37310126, 0),\n",
       " (0.3725368, 0),\n",
       " (0.36653328, 0),\n",
       " (0.36565292, 0),\n",
       " (0.3615607, 0),\n",
       " (0.35916957, 0),\n",
       " (0.3549003, 0),\n",
       " (0.35322148, 1),\n",
       " (0.3507331, 0),\n",
       " (0.34017673, 1),\n",
       " (0.3383481, 0),\n",
       " (0.33461347, 0),\n",
       " (0.3239176, 1),\n",
       " (0.32178935, 0),\n",
       " (0.28587693, 0),\n",
       " (0.28293937, 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_with_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61600953, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_split_point(sequence):\n",
    "    count_ones = 0\n",
    "    count_zeros = 0\n",
    "    max_diff = -1\n",
    "    split_point = -1\n",
    "    \n",
    "    for i, bit in enumerate(sequence):\n",
    "        if bit == 1:\n",
    "            count_ones += 1\n",
    "        else:\n",
    "            count_zeros += 1\n",
    "        \n",
    "        diff = count_ones - count_zeros\n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "            split_point = i\n",
    "    \n",
    "    return split_point\n",
    "\n",
    "split_point = find_split_point(labels)\n",
    "value = scores_with_labels_train[split_point]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = []\n",
    "thresh = value[0]\n",
    "for i in scores_with_labels_test:\n",
    "    if i[0] > thresh:\n",
    "        preds.append(1==i[1])\n",
    "    else:\n",
    "        preds.append(0==i[1])\n",
    "sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute cluster correlation across formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "cluster_vectors = []\n",
    "\n",
    "def group_clusters(embedding, cluster_labels):\n",
    "    cluster_0 = []\n",
    "    cluster_1 = []\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        if label == 0:\n",
    "            cluster_0.append(embedding[i])\n",
    "        else:\n",
    "            cluster_1.append(embedding[i])\n",
    "    # get average embedding for each cluster\n",
    "    cluster_0_avg = np.mean(cluster_0, axis=0)\n",
    "    cluster_1_avg = np.mean(cluster_1, axis=0)\n",
    "    return (cluster_0_avg, cluster_1_avg)\n",
    "\n",
    "def get_cluster_vectors(embedding):\n",
    "    clusterer = KMeans(n_clusters=2, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(embedding)\n",
    "    silhouette_avg = silhouette_score(embedding, cluster_labels)\n",
    "    if silhouette_avg > value[0]:\n",
    "        return group_clusters(embedding, cluster_labels)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "for embedding in embs['train']:\n",
    "    vecs = get_cluster_vectors(embedding['embs'])\n",
    "    if vecs != None:\n",
    "        cluster_vectors.append(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.21540566,  0.04394149, -0.8167139 ,  0.93003595, -0.97237647,\n",
       "        -0.86760235, -0.88844824, -0.7071766 , -0.8585163 , -0.9751871 ,\n",
       "        -0.58062494,  0.9863596 ,  0.8402313 ,  0.6771322 ,  0.33159262,\n",
       "        -0.73869634], dtype=float32),\n",
       " array([-0.72970885,  0.04942944,  0.9779272 , -0.71400034, -0.9095677 ,\n",
       "         0.048223  , -0.62863165,  0.10765669, -0.9106606 , -0.85211015,\n",
       "        -0.8941389 ,  0.97597337, -0.03721797, -0.14009655,  0.879907  ,\n",
       "        -0.2283434 ], dtype=float32))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vecs = [i for i,j in cluster_vectors] + [j for i,j in cluster_vectors]\n",
    "mean_vecs = np.array(mean_vecs)\n",
    "truth_vecs = get_cluster_vectors(mean_vecs)\n",
    "truth_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
